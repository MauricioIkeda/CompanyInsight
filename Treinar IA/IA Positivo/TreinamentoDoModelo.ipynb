{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbqXeONNUsAQ",
    "outputId": "387df46a-01aa-4b9c-d749-08280678ffd0"
   },
   "outputs": [],
   "source": [
    "! pip install -U spacy -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8hvZt0qUvfA",
    "outputId": "dfb808c0-d52a-4f7b-8bf9-287ea2a383d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    3.8.2                         \n",
      "Location         c:\\Users\\kingu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\n",
      "Platform         Windows-11-10.0.26100-SP0     \n",
      "Python version   3.12.7                        \n",
      "Pipelines        pt_core_news_lg (3.8.0)       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpnjAZIDU5qJ",
    "outputId": "0aebb9d9-805b-48e8-98bb-9eb9068d7bc3"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/amrrs/custom-ner-with-spacy/main/pvr_training_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CYc4PoUJZgVI"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.blank(\"pt\")\n",
    "db = DocBin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ypmHuPYBZ7C0"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "TRAIN_DATAS = []\n",
    "\n",
    "with open('training_data1.json', encoding='utf-8') as f:\n",
    "    TRAIN_DATAS.append(json.load(f))\n",
    "\n",
    "with open('training_data2.json', encoding='utf-8') as f:\n",
    "    TRAIN_DATAS.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRGQF9p2VKss",
    "outputId": "205de197-2cd9-4255-ee1f-dde5dc86ebb8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [00:00<00:00, 1407.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:00<00:00, 1829.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for TRAIN_DATA in TRAIN_DATAS:\n",
    "    for text, annot in tqdm(TRAIN_DATA['annotations']): \n",
    "        doc = nlp.make_doc(text) \n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents \n",
    "        db.add(doc)\n",
    "\n",
    "db.to_disk(\"./training_data.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SECGYS_KVUHF",
    "outputId": "52cec175-2d54-406d-cd06-a12d659009a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: pt\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy init config config.cfg --lang pt --pipeline ner --optimize efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT82H_hqWaGP",
    "outputId": "116c82f1-1c8d-469c-bfa1-a816fa7cb896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     36.18    1.51    0.83    8.67    0.02\n",
      "  0     200      10470.71   4459.56   34.19   49.80   26.04    0.34\n",
      "  0     400       4362.96   1607.31   36.33   61.40   25.80    0.36\n",
      "  0     600        392.82   1332.00   47.75   58.99   40.11    0.48\n",
      "  0     800       4338.11   1486.55   43.81   67.48   32.43    0.44\n",
      "  1    1000        353.11   1299.13   52.72   63.50   45.06    0.53\n",
      "  1    1200        133.88   1375.74   54.08   74.25   42.52    0.54\n",
      "  1    1400        167.28   1524.68   46.66   79.79   32.97    0.47\n",
      "  2    1600       1898.03   1968.38   59.09   77.95   47.58    0.59\n",
      "  2    1800        522.69   2007.63   63.97   72.90   57.00    0.64\n",
      "  3    2000        263.48   2271.45   64.31   65.65   63.02    0.64\n",
      "  3    2200        883.30   2683.47   68.44   75.34   62.70    0.68\n",
      "  4    2400        935.00   3099.36   71.07   73.77   68.56    0.71\n",
      "  5    2600       5376.53   3744.83   72.78   80.62   66.34    0.73\n",
      "  7    2800       3380.58   3686.42   74.70   74.22   75.19    0.75\n",
      "  8    3000       2412.11   3271.39   76.98   77.96   76.02    0.77\n",
      "  9    3200       1596.90   3142.66   79.91   80.54   79.29    0.80\n",
      " 10    3400       3000.29   3124.85   82.51   83.82   81.24    0.83\n",
      " 12    3600       2222.03   2717.38   84.28   83.83   84.75    0.84\n",
      " 13    3800       2446.71   2499.25   85.99   86.18   85.79    0.86\n",
      " 14    4000       2678.61   2374.73   85.76   88.64   83.06    0.86\n",
      " 15    4200       2207.27   2363.29   86.79   89.53   84.21    0.87\n",
      " 16    4400       1166.84   2129.90   86.97   86.28   87.66    0.87\n",
      " 18    4600      12519.29   2196.35   88.50   88.01   89.00    0.89\n",
      " 19    4800      13016.73   2087.53   89.91   89.91   89.91    0.90\n",
      " 20    5000       1018.85   1875.64   90.70   91.80   89.62    0.91\n",
      " 21    5200       1040.25   1710.23   88.90   90.86   87.02    0.89\n",
      " 23    5400       1037.41   1687.03   91.68   90.25   93.15    0.92\n",
      " 24    5600       2549.08   1620.69   91.91   91.89   91.92    0.92\n",
      " 25    5800        956.77   1646.28   92.10   90.99   93.23    0.92\n",
      " 26    6000       1173.58   1534.93   92.17   91.02   93.34    0.92\n",
      " 28    6200      13525.71   1640.44   93.45   92.86   94.03    0.93\n",
      " 29    6400        839.14   1318.08   91.36   91.36   91.36    0.91\n",
      " 30    6600        975.97   1312.85   93.16   92.44   93.90    0.93\n",
      " 31    6800       1048.43   1361.92   94.06   93.85   94.27    0.94\n",
      " 32    7000       1071.72   1319.90   94.04   92.49   95.64    0.94\n",
      " 34    7200        925.24   1218.96   94.28   94.54   94.03    0.94\n",
      " 35    7400       1075.35   1253.20   94.30   94.93   93.68    0.94\n",
      " 36    7600      14035.62   1361.15   93.99   94.39   93.60    0.94\n",
      " 37    7800       1049.38   1201.48   94.02   93.24   94.81    0.94\n",
      " 39    8000       1067.88   1171.30   94.68   94.63   94.73    0.95\n",
      " 40    8200       1783.33   1093.47   94.68   95.04   94.33    0.95\n",
      " 41    8400       2735.97   1055.42   94.95   94.89   95.00    0.95\n",
      " 42    8600       1097.59   1071.74   95.09   95.30   94.89    0.95\n",
      " 43    8800       1294.43   1035.43   94.70   94.92   94.49    0.95\n",
      " 45    9000       1022.59   1050.51   94.86   94.38   95.34    0.95\n",
      " 46    9200      33763.55   1225.27   95.16   95.35   94.97    0.95\n",
      " 47    9400       1121.14   1024.70   95.23   95.73   94.73    0.95\n",
      " 48    9600       1238.86   1087.65   95.48   96.27   94.70    0.95\n",
      " 50    9800       1567.89    991.01   95.71   94.99   96.44    0.96\n",
      " 51   10000       1339.27    929.41   94.80   95.47   94.14    0.95\n",
      " 52   10200       1026.71    937.05   95.35   94.65   96.07    0.95\n",
      " 53   10400       1101.29    955.68   95.61   97.23   94.03    0.96\n",
      " 54   10600       1074.84    923.48   95.67   96.56   94.78    0.96\n",
      " 56   10800       1084.57    864.69   95.91   95.51   96.31    0.96\n",
      " 57   11000       1530.58    937.56   95.69   96.36   95.02    0.96\n",
      " 58   11200       1162.46    844.57   95.40   95.42   95.37    0.95\n",
      " 59   11400       1192.26    874.69   95.72   95.18   96.25    0.96\n",
      " 61   11600       1031.22    796.15   95.78   95.36   96.20    0.96\n",
      " 62   11800       1331.60    859.80   95.59   95.27   95.91    0.96\n",
      " 63   12000       1446.05    827.05   95.90   96.28   95.53    0.96\n",
      " 64   12200       1712.89    834.13   96.25   97.06   95.45    0.96\n",
      " 66   12400       1165.52    842.26   96.12   96.05   96.20    0.96\n",
      " 67   12600       1190.50    766.53   96.14   96.60   95.69    0.96\n",
      " 68   12800       1140.38    822.88   95.74   96.54   94.94    0.96\n",
      " 69   13000       1405.27    773.51   96.03   96.16   95.91    0.96\n",
      " 70   13200       2229.13    831.71   96.24   97.03   95.45    0.96\n",
      " 72   13400       1517.28    742.73   95.75   96.78   94.76    0.96\n",
      " 73   13600       1746.00    769.06   96.18   95.61   96.76    0.96\n",
      " 74   13800       1343.37    736.94   95.71   95.89   95.53    0.96\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "model-last\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8zljPkppcy_w"
   },
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load(\"model-last\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GTbWEZ9Cc9b4"
   },
   "outputs": [],
   "source": [
    "doc = nlp_ner('''meu celular da Positivo parou de ligar a tela''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oBNf3_JGWzB9",
    "outputId": "800fb73d-817b-42af-dc2a-5726df1cef48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">meu \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    celular\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUTO</span>\n",
       "</mark>\n",
       " da \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Positivo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MARCA</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    parou de ligar a tela\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MOTIVO</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Custom NER with Spacy3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
